{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Capstone_dataset_v1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1RlHBEPIe3Hw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634301642981,"user_tz":-330,"elapsed":361,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"61c27734-caa3-4d6a-c115-f0da7eac876b"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Oct 15 12:40:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"5xws0ct4fF9H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634301668046,"user_tz":-330,"elapsed":19526,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"cf5a87c8-2edb-43fa-9d9d-95a1beb4e298"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"fSR0EZhNfwIg"},"source":["# !mkdir /content/drive/MyDrive/EVA6/Capstone/dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"maRbq_dNfQeK"},"source":["# !unzip /content/drive/MyDrive/EVA6/Capstone/construction_materials_dataset.zip -d /content/drive/MyDrive/EVA6/Capstone/dataset/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bi3fAtIMinXR"},"source":["# !git clone https://github.com/facebookresearch/detr.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTYO4cxstpSg"},"source":["# !rm -rf /content/EVA6_Capstone"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3g51rlWsIhd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634301672359,"user_tz":-330,"elapsed":1147,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"1a9bd446-321f-4d4d-8e2b-d3ea7fa7ff5a"},"source":["!git clone https://github.com/gokul-pv/EVA6_Capstone"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'EVA6_Capstone'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Counting objects: 100% (39/39), done.\u001b[K\n","remote: Compressing objects: 100% (28/28), done.\u001b[K\n","remote: Total 39 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (39/39), done.\n"]}]},{"cell_type":"code","metadata":{"id":"mq0aH0PaF06z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634301682105,"user_tz":-330,"elapsed":5709,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"ce450692-dab6-44a1-8ff6-db10b0906986"},"source":["! pip install git+https://github.com/cocodataset/panopticapi.git"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/cocodataset/panopticapi.git\n","  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-kme4aofz\n","  Running command git clone -q https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-kme4aofz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from panopticapi==0.1) (1.19.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from panopticapi==0.1) (7.1.2)\n","Building wheels for collected packages: panopticapi\n","  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8306 sha256=138314353f1132542a071b736cea983571cbdb0f96a122c5255b625980d07c14\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-e1jmz0ff/wheels/ad/89/b8/b66cce9246af3d71d65d72c85ab993fd28e7578e1b0ed197f1\n","Successfully built panopticapi\n","Installing collected packages: panopticapi\n","Successfully installed panopticapi-0.1\n"]}]},{"cell_type":"code","metadata":{"id":"LSSFZO3xieU5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302163595,"user_tz":-330,"elapsed":947,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"e20bd443-88fe-4ac4-9ae1-5d07b252d01e"},"source":["import os\n","import sys\n","import numpy as np\n","import torch\n","print(torch.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu111\n"]}]},{"cell_type":"code","metadata":{"id":"1wU298KGs0oT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302177856,"user_tz":-330,"elapsed":361,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"dfb3a54e-0346-497b-e0c8-57004fad3bf5"},"source":["# sys.path.append(os.path.join(os.getcwd(), \"detr/\"))\n","sys.path.append(os.path.join(os.getcwd(), \"/content/EVA6_Capstone/\"))\n","print(sys.path)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/EVA6_Capstone/']\n"]}]},{"cell_type":"code","metadata":{"id":"xyyRuTiViv9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302179316,"user_tz":-330,"elapsed":9,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"af045582-c9f0-411c-8606-b098c3c8c9b6"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","use_cuda, device"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, device(type='cuda'))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"rWawN1FvjhEw","executionInfo":{"status":"ok","timestamp":1634302181566,"user_tz":-330,"elapsed":348,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["import torchvision.transforms as T\n","\n","# standard PyTorch mean-std input image normalization\n","transform = T.Compose([\n","    T.Resize(800),\n","    T.ToTensor(),\n","    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhgEIGMLkAfA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302188031,"user_tz":-330,"elapsed":4985,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"a828a690-281b-4eee-d0ce-c85c63b55212"},"source":["# Load detr model\n","model, postprocessor = torch.hub.load('facebookresearch/detr', 'detr_resnet101_panoptic', pretrained=True, return_postprocessor=True, num_classes=250)\n","# Convert to eval mode\n","model = model.to(device)\n","model.eval()\n","\n","print(\"Model Loaded\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/facebookresearch_detr_master\n"]},{"output_type":"stream","name":"stdout","text":["Model Loaded\n"]}]},{"cell_type":"code","metadata":{"id":"WfHvKTsWkZ2r","executionInfo":{"status":"ok","timestamp":1634302213088,"user_tz":-330,"elapsed":346,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["data_path = [\n","      '/content/drive/MyDrive/EVA6/Capstone/dataset/aac_blocks'\n","]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3VMMAR_k1Mh","executionInfo":{"status":"ok","timestamp":1634302213695,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["def convert(o):\n","    if isinstance(o, np.generic): return o.item()  \n","    raise TypeError"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tCNfkgKsY-Z","executionInfo":{"status":"ok","timestamp":1634302214990,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from DatasetCreation import COCO_CATEGORIES, CUSTOM_CATEGORIES, COCO_NAMES, MAPPINGS, INFO, LICENSES, cat2id"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"95rOTKFEk-EE","executionInfo":{"status":"ok","timestamp":1634302216116,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["ROOT_DIR = '/content/drive/MyDrive/EVA6/Capstone/dataset'\n","\n","processing_file = \"\"\n","processing_data = []\n","\n","image_id = 1\n","annotation_id = 1\n","segment_id = 1\n","\n","GLOBAL_COCO = {\n","    \"licenses\": LICENSES,\n","    \"info\": INFO,\n","    \"categories\": CUSTOM_CATEGORIES,\n","    \"annotations\": [],\n","    \"images\": []\n","}\n","\n","GLOBAL_PANOPTIC = {\n","    \"licenses\": LICENSES,\n","    \"info\": INFO,\n","    \"categories\": CUSTOM_CATEGORIES,\n","    \"annotations\": [],\n","    \"images\": []\n","}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OSOdhVf49pJ","executionInfo":{"status":"ok","timestamp":1634302219327,"user_tz":-330,"elapsed":578,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["import datetime\n","import time\n","import json\n","import traceback"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuqvJE8Y5Aa6","executionInfo":{"status":"ok","timestamp":1634302219896,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from PIL import Image, ImageDraw, ImageFont\n","from panopticapi.utils import id2rgb, rgb2id\n","import io"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYYDjSOdyfOC"},"source":["############################ Create DATASET ################################\n","\n","# run through all folders in dataset\n","for category_path in data_path:\n","    # store starting time\n","    start = time.time()\n","    # get category name\n","    category_name = category_path.split(\"/\")[7]\n","    print(\"Processing Category:\", category_name)\n","\n","    # open category coco file\n","    with open(os.path.join(category_path, \"coco.json\"), \"r\") as coco_file:\n","        category_coco = json.load(coco_file)\n","        \n","    images_root = os.path.join(category_path, 'images')\n","    \n","    TEMP_COCO_IMAGES = {}\n","    \n","    # Run over all images\n","    for im in category_coco[\"images\"]:\n","        im['annotations'] = []\n","        TEMP_COCO_IMAGES[im['id']] = im\n","        \n","    for ann in category_coco[\"annotations\"]:\n","        TEMP_COCO_IMAGES[ann['image_id']][\"annotations\"].append(ann)\n","\n","      \n","    for i, image_coco in TEMP_COCO_IMAGES.items():\n","        # get image path\n","        ## This data can be used further for logging if failed while processing\n","        processing_file = os.path.join(images_root, image_coco['file_name'])\n","        processing_data = image_coco\n","        output_file_name = category_name + \"_\" + str(image_id) + \".jpg\"\n","        output_file_path = os.path.join(ROOT_DIR, \"images\", output_file_name)\n","        \n","        output_mask_name = category_name + \"_\" + str(image_id) + \".png\"\n","        output_mask_path = os.path.join(ROOT_DIR, \"masks\", output_mask_name)\n","\n","        try:\n","\n","          # Read this image and get shape of image\n","          imo = Image.open(processing_file).convert('RGB')\n","\n","          try:\n","              h, w, c = np.array(imo).shape\n","          except:\n","              h, w = np.array(imo).shape\n","              c = 1\n","\n","          # if no of channels != 3, open the image and convert it to 3 channel - RGB\n","          if c == 4 or c == 1:\n","              imo = imo.convert('RGB')\n","              h, w, c = np.array(imo).shape\n","\n","          # Create a copy of image this will be used for further processing\n","          im = imo.copy()\n","\n","          # Apply transform and convert image to batch\n","          # mean-std normalize the input image (batch-size: 1)\n","          img = transform(im).unsqueeze(0).to(device)  # [h, w, c] -> [1, c, ht, wt]\n","\n","          # Generate output for image\n","          out = model(img)\n","\n","          # Generate score\n","          # compute the scores, excluding the \"no-object\" class (the last one)\n","          scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n","\n","          # threshold the confidence\n","          keep = scores > 0.85\n","\n","          # Keep only ones above threshold\n","          pred_logits, pred_boxes = out[\"pred_logits\"][keep][:, :len(COCO_NAMES) - 1], out[\"pred_boxes\"][keep] \n","  \n","          # the post-processor expects as input the target size of the predictions (which we set here to the image size)\n","          result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]\n","          \n","          # The segmentation is stored in a special-format png\n","          panoptic_seg = Image.open(io.BytesIO(result['png_string'])).resize((w, h), Image.NEAREST)\n","          # (wp, hp) = panoptic_seg.size\n","          panoptic_seg = np.array(panoptic_seg, dtype=np.uint8).copy()   \n","\n","          # We retrieve the ids corresponding to each mask\n","          panoptic_seg_id = rgb2id(panoptic_seg)\n","\n","          # Merge predicted annotations      \n","          # 1. Get Mapping from predicted id to new ids\n","\n","          unique_category_id = []\n","          for i, segment in enumerate(result['segments_info']):\n","              result['segments_info'][i][\"category_id\"] = MAPPINGS[result['segments_info'][i][\"category_id\"]]\n","              if result['segments_info'][i][\"category_id\"] not in unique_category_id:\n","                  unique_category_id.append(result['segments_info'][i][\"category_id\"])\n","\n","          # Sort array\n","          unique_category_id.sort()\n","          \n","          unique_category_id_to_id =  {category_id: i for i, category_id in enumerate(unique_category_id)}\n","          unique_id_to_category_id =  {i: category_id for category_id, i in unique_category_id_to_id.items()}\n","          \n","          for i, segment in enumerate(result['segments_info']):\n","              result['segments_info'][i][\"new_id\"] = unique_category_id_to_id[result['segments_info'][i][\"category_id\"]]\n","          \n","          # Update original panoptic_seg_id array with new ids as the new segmentation combines different categories.\n","          custom_panoptic_seg_id = np.zeros((panoptic_seg_id.shape[0], panoptic_seg_id.shape[1]), dtype=np.uint8)\n","          \n","          # Update this custom panoptic seg matrix\n","          for i, segment in enumerate(result['segments_info']):\n","              custom_panoptic_seg_id[result['segments_info'][i]['id'] == panoptic_seg_id] = result['segments_info'][i]['new_id']\n","              \n","          # Create new Segmentation info\n","          # [{'area': 243, 'category_id': 3, 'id': 0, 'isthing': True},\n","          #   {'area': 730578, 'category_id': 184, 'id': 1, 'isthing': False}]\n","          \n","          custom_panoptic_segments_info = []\n","          for category_id in unique_category_id:\n","              custom_panoptic_segments_info.append({\n","                  'segment_id': unique_category_id_to_id[category_id], \n","                  'category_id': category_id,\n","                  'bbox': [],\n","                  'area': 0,\n","                  'iscroud': 0,\n","                  'isthing': 0\n","              })\n","\n","          # annotations of our construction things\n","          omask = processing_data['annotations']\n","          \n","          TEMP_ANNOTATIONS = []\n","          \n","          # Overlay things mask one at a time\n","          for annotation in omask:\n","              # overlay mask of construction things on top of detr output\n","              omask_image_id = get_overlayed_mask((h, w), annotation)\n","              custom_panoptic_seg_id[omask_image_id.astype(np.bool_)] = custom_panoptic_seg_id.max() + 1\n","              custom_panoptic_segments_info.append({\n","                  'segment_id': custom_panoptic_seg_id.max(), \n","                  'category_id': cat2id[category_name], \n","                  'bbox': annotation['bbox'],\n","                  'area': annotation['area'],\n","                  'iscroud': 0,\n","                  'isthing': 1\n","              })\n","\n","              # append annotation of construction things in json file\n","              annotation[\"category_id\"] = cat2id[category_name]\n","              annotation[\"image_id\"] = image_id\n","              TEMP_ANNOTATIONS.append(annotation)\n","            \n","          # Convert to binary segment\n","          binary_masks = np.zeros((\n","              custom_panoptic_seg_id.max() + 1,\n","              custom_panoptic_seg_id.shape[0],\n","              custom_panoptic_seg_id.shape[1]),\n","              dtype=np.uint8\n","          )\n","              \n","          # for each binary mask, detect contours and create annotation for those contours\n","          if len(unique_category_id):\n","              # Skip the onse which are added by us\n","              for category_id in unique_category_id:\n","                  binary_masks[unique_category_id_to_id[category_id], :, :] = custom_panoptic_seg_id == unique_category_id_to_id[category_id]\n","                  annotation_info = coco_main(binary_masks[unique_category_id_to_id[category_id]], None, image_id, category_id, unique_category_id_to_id[category_id], 0)\n","                  if annotation_info is not None:\n","                      annotation_info[\"image_id\"] = image_id\n","                      annotation_info[\"category_id\"] = category_id\n","                      TEMP_ANNOTATIONS.append(annotation_info)\n","                      \n","                      custom_panoptic_segments_info[unique_category_id_to_id[category_id]]['bbox'] = annotation_info['bbox']\n","                      custom_panoptic_segments_info[unique_category_id_to_id[category_id]]['area'] = annotation_info['area']\n","          else:\n","              # Do something for the once where there are no predictions\n","              ## Probably mark them as None\n","              pass\n","\n","          # Write data to global json and save files to image dir's\n","          \n","          # save image to new path as .jpg\n","          imo.save(output_file_path)\n","          \n","          # save panoptic image\n","          Image.fromarray(id2rgb(custom_panoptic_seg_id), 'RGB').save(output_mask_path)\n","\n","          # create image_info object and append it to original list\n","          image_info = create_image_info(image_id, output_file_name, imo.size)\n","          image_info[\"original_file\"] = processing_file\n","\n","          GLOBAL_COCO[\"images\"].append(image_info)\n","          GLOBAL_PANOPTIC[\"images\"].append(image_info)\n","\n","          for annotation in TEMP_ANNOTATIONS:\n","              annotation[\"id\"] = annotation_id\n","              GLOBAL_COCO[\"annotations\"].append(annotation)\n","              annotation_id += 1\n","              \n","          for segment_info in custom_panoptic_segments_info:\n","              segment_info[\"id\"] = segment_id\n","              segment_id += 1\n","              \n","          GLOBAL_PANOPTIC[\"annotations\"].append({\n","              \"segments_info\": custom_panoptic_segments_info,\n","              \"file_name\": output_mask_name,\n","              \"image_id\": image_id\n","          })\n","\n","          # increment the image_count\n","          image_id += 1\n","\n","        except Exception as e:\n","            # if there is any error, add info about it in errros file and procees to next image\n","            print(\"Error occurred while processig file:\", processing_file)\n","            \n","            with open(os.path.join(ROOT_DIR, \"error.json\"), 'r') as error_file:\n","                error_json = json.load(error_file)\n","                \n","            with open(os.path.join(ROOT_DIR, \"error.json\"), 'w') as error_file:\n","                error_json[\"error\"].append({\n","                    \"processing_file\": processing_file,\n","                    \"processing_data\": processing_data\n","                })\n","                \n","                json.dump(error_json, error_file)\n","                \n","            traceback.print_exc()\n","        del img   \n","        torch.cuda.empty_cache() \n","        # break\n","    total_time_str = str(datetime.timedelta(seconds=int(time.time() - start)))\n","    print(f\"Completed Category: {category_name}, Time Taken: {total_time_str}\")\n","\n","    # open the final json, and commit changes in that file\n","    with open(os.path.join(ROOT_DIR, \"coco.json\"), 'w') as output_json_file:\n","        json.dump(GLOBAL_COCO, output_json_file)\n","        \n","    with open(os.path.join(ROOT_DIR, \"panoptic.json\"), 'w') as output_json_file:\n","        json.dump(GLOBAL_PANOPTIC, output_json_file, default=convert)\n","        \n","    print(image_id, annotation_id, segment_id)\n","         \n","         "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvZShMBK-iHA","executionInfo":{"status":"ok","timestamp":1634302320503,"user_tz":-330,"elapsed":1138,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["!rm -rf /content/drive/MyDrive/EVA6/Capstone/dataset/images/*\n","!rm -rf /content/drive/MyDrive/EVA6/Capstone/dataset/masks/*\n","!rm -rf /content/drive/MyDrive/EVA6/Capstone/dataset/coco.json\n","!rm -rf /content/drive/MyDrive/EVA6/Capstone/dataset/panoptic.json"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnVV8SGoas6h","executionInfo":{"status":"ok","timestamp":1634302228555,"user_tz":-330,"elapsed":349,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from math import floor\n","import cv2\n","def get_overlayed_mask(image_size, annotations):\n","    height, width = image_size\n","    # # create a single channel height, width pixel black image\n","    blank_image = np.zeros((height, width))\n","\n","    ## Show Code image\n","    # plt.imshow(image)\n","    # plt.show()\n","\n","    # Create list of polygons to be drawn\n","    # for i, annotation in enumerate(annotations):\n","    polygons_list = []\n","    # Add the polygon segmentation\n","    for segmentation_points in annotations[\"segmentation\"]:\n","        segmentation_points = np.multiply(segmentation_points, 1).astype(int)\n","        polygons_list.append(segmentation_points)\n","\n","    for x in polygons_list:\n","        end = []\n","        if len(x) % 2 != 0:\n","            print(x)\n","        for l in range(0, len(x), 2):\n","            coords = [floor(x[l]), floor(x[l + 1])]\n","            end.append(coords)\n","        contours = np.array(end)\n","        if end == []:\n","            continue\n","        cv2.fillPoly(blank_image, pts=[contours], color=(1, 1, 1))\n","        ## Plot final image\n","        # plt.imshow(image)\n","        # plt.show()\n","    return blank_image"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rhPJpj9vc-j","executionInfo":{"status":"ok","timestamp":1634302245325,"user_tz":-330,"elapsed":359,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["def coco_main(binary_mask, image_size, image_id, class_id, segmentation_id, iscrowd):\n","\n","    ## --------- Prepare coco format from binary masks -------\n","\n","    # {\n","    #     \"id\": 1,\n","    #     \"image_id\": 1,\n","    #     \"category_id\": 1,\n","    #     \"segmentation\": [\n","    #         []\n","    #     ],\n","    #     \"area\": 368501.0,\n","    #     \"bbox\": [\n","    #         0.0,\n","    #         74.18,\n","    #         751.32,\n","    #         544.58\n","    #     ],\n","    #     \"iscrowd\": 0,\n","    #     \"attributes\": {\n","    #         \"occluded\": false\n","    #     }\n","    # },\n","\n","    category_info = {\"id\": class_id, \"is_crowd\": iscrowd}\n","\n","    annotation_info = create_annotation_info(\n","        segmentation_id, image_id, category_info, binary_mask, image_size, tolerance=2\n","    )\n","\n","    return annotation_info"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEfOAtpfvzZZ","executionInfo":{"status":"ok","timestamp":1634302247336,"user_tz":-330,"elapsed":355,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from pycocotools import mask\n","def create_annotation_info(\n","    annotation_id,\n","    image_id,\n","    category_info,\n","    binary_mask,\n","    image_size=None,\n","    tolerance=2,\n","    bounding_box=None,\n","):\n","\n","    if image_size is not None:\n","        binary_mask = resize_binary_mask(binary_mask, image_size)\n","\n","    binary_mask_encoded = mask.encode(np.asfortranarray(binary_mask.astype(np.uint8)))\n","\n","    area = mask.area(binary_mask_encoded)\n","    if area < 1:\n","        return None\n","\n","    if bounding_box is None:\n","        bounding_box = mask.toBbox(binary_mask_encoded)\n","\n","    if category_info[\"is_crowd\"]:\n","        is_crowd = 1\n","        segmentation = binary_mask_to_rle(binary_mask)\n","    else:\n","        is_crowd = 0\n","        segmentation = binary_mask_to_polygon(binary_mask, tolerance)\n","        if not segmentation:\n","            return None\n","\n","    annotation_info = {\n","        \"id\": annotation_id,\n","        \"image_id\": image_id,\n","        \"category_id\": category_info[\"id\"],\n","        \"iscrowd\": is_crowd,\n","        \"area\": area.tolist(),\n","        \"bbox\": bounding_box.tolist(),\n","        \"segmentation\": segmentation,\n","        \"width\": binary_mask.shape[1],\n","        \"height\": binary_mask.shape[0],\n","    }\n","\n","    return annotation_info"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"X38qttofwSO5","executionInfo":{"status":"ok","timestamp":1634302250001,"user_tz":-330,"elapsed":343,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from skimage import measure\n","def binary_mask_to_polygon(binary_mask, tolerance=0):\n","    \"\"\"Converts a binary mask to COCO polygon representation\n","\n","    Args:\n","        binary_mask: a 2D binary numpy array where '1's represent the object\n","        tolerance: Maximum distance from original points of polygon to approximated\n","            polygonal chain. If tolerance is 0, the original coordinate array is returned.\n","\n","    \"\"\"\n","    polygons = []\n","    # pad mask to close contours of shapes which start and end at an edge\n","    padded_binary_mask = np.pad(\n","        binary_mask, pad_width=1, mode=\"constant\", constant_values=0\n","    )\n","    contours = measure.find_contours(padded_binary_mask, 0.5)\n","    contours = np.subtract(contours, 1)\n","    for contour in contours:\n","        contour = close_contour(contour)\n","        contour = measure.approximate_polygon(contour, tolerance)\n","        if len(contour) < 3:\n","            continue\n","        contour = np.flip(contour, axis=1)\n","        segmentation = contour.ravel().tolist()\n","        # after padding and subtracting 1 we may get -0.5 points in our segmentation\n","        segmentation = [0 if i < 0 else i for i in segmentation]\n","        polygons.append(segmentation)\n","\n","    return polygons"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"aC3-apaQwka0","executionInfo":{"status":"ok","timestamp":1634302251433,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["def close_contour(contour):\n","    if not np.array_equal(contour[0], contour[-1]):\n","        contour = np.vstack((contour, contour[0]))\n","    return contour"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"DchLMVc7xHSB","executionInfo":{"status":"ok","timestamp":1634302254221,"user_tz":-330,"elapsed":333,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["def create_image_info(\n","    image_id,\n","    file_name,\n","    image_size,\n","    date_captured=datetime.datetime.utcnow().isoformat(\" \"),\n","    license_id=1,\n","    coco_url=\"\",\n","    flickr_url=\"\",\n","):\n","\n","    image_info = {\n","        \"id\": image_id,\n","        \"file_name\": file_name,\n","        \"width\": image_size[0],\n","        \"height\": image_size[1],\n","        \"date_captured\": date_captured,\n","        \"license\": license_id,\n","    }\n","\n","    return image_info"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"THtdxSh40lAw","executionInfo":{"status":"ok","timestamp":1634302255691,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["from itertools import groupby\n","\n","def binary_mask_to_rle(binary_mask):\n","    rle = {\"counts\": [], \"size\": list(binary_mask.shape)}\n","    counts = rle.get(\"counts\")\n","    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order=\"F\"))):\n","        if i == 0 and value == 1:\n","            counts.append(0)\n","        counts.append(len(list(elements)))\n","\n","    return rle"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO3YGcZ607TQ","executionInfo":{"status":"ok","timestamp":1634302257153,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["def resize_binary_mask(array, new_size):\n","    image = Image.fromarray(array.astype(np.uint8) * 255)\n","    image = image.resize(new_size)\n","    return np.asarray(image).astype(np.bool_)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8yVJ47glKn-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302259270,"user_tz":-330,"elapsed":519,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"177891f6-0891-4836-f48b-c9c6e6c95730"},"source":["# setting device on GPU if available, else CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","Tesla P100-PCIE-16GB\n","Memory Usage:\n","Allocated: 0.2 GB\n","Cached:    0.2 GB\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:375: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"LOcf27MlmGbz","executionInfo":{"status":"ok","timestamp":1634302198043,"user_tz":-330,"elapsed":441,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}}},"source":["torch.cuda.empty_cache()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUKP_HUacJLq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634302490549,"user_tz":-330,"elapsed":370,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"03c0ca89-4ec4-442f-ea3b-186e52bcb19e"},"source":["print(torch.cuda.get_device_properties(device))"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RFs3jBDBdvp","executionInfo":{"status":"ok","timestamp":1634302847008,"user_tz":-330,"elapsed":339,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"430f470e-378c-4d4f-f585-c222bd781259"},"source":["torch.cuda.max_memory_allocated()/1024**3"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14.062496185302734"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzCcNk_LDI1R","executionInfo":{"status":"ok","timestamp":1634302989908,"user_tz":-330,"elapsed":383,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"f548e5ed-0917-4f7a-ac1d-1f28926ba53e"},"source":["!ps -aux|grep python"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["root          79  0.1  0.2 194924 60936 ?        Sl   12:11   0:04 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --MappingKernelManager.root_dir=\"/content\"\n","root         327  0.0  0.0  18380  2964 ?        S    12:41   0:00 bash -c tail -n +0 -F \"/root/.config/Google/DriveFS/Logs/drive_fs.txt\" | python3 /opt/google/drive/drive-filter.py > \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" \n","root         329  0.0  0.0  31740  9672 ?        S    12:41   0:00 python3 /opt/google/drive/drive-filter.py\n","root         475  5.8 15.0 39700884 4014956 ?    Ssl  12:49   0:49 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-0b4ee356-0a5c-49cb-8d5e-a20eff40822e.json\n","root         495  0.3  0.0 128408 16072 ?        Sl   12:49   0:02 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 45135 --host 127.0.0.1 --port 16437 --server-access-token 7d866b28f28ae758002c38acbb9c1a67b4f23aa1b483d8113563bf0bc5c7b504\n","root         629  0.0  0.0  39200  6516 ?        S    13:03   0:00 /bin/bash -c ps -aux|grep python\n","root         631  0.0  0.0  38572  5648 ?        S    13:03   0:00 grep python\n"]}]}]}