{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"construction_dataset_creation_v5.ipynb","provenance":[{"file_id":"1MvSjQUWvy4Fm93hmImkJSfdicN4Pz8bV","timestamp":1634304723740}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1RlHBEPIe3Hw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636205811028,"user_tz":-330,"elapsed":721,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"cfb6e177-3df0-4210-9636-0f2dd800407e"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Nov  6 13:36:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    39W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"5xws0ct4fF9H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636178365113,"user_tz":-330,"elapsed":30814,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"fbd5181e-8c33-4984-dfaf-6ff1190318f2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"fSR0EZhNfwIg"},"source":["# !mkdir /content/drive/MyDrive/EVA6/Capstone/dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"maRbq_dNfQeK"},"source":["# !unzip /content/drive/MyDrive/EVA6/Capstone/construction_materials_dataset.zip -d /content/drive/MyDrive/EVA6/Capstone/dataset/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3g51rlWsIhd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636191245686,"user_tz":-330,"elapsed":3030,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"1cb8007d-cbd0-486a-8605-abb782ea07eb"},"source":["! git clone https://github.com/gokul-pv/EVA6_Capstone"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'EVA6_Capstone'...\n","remote: Enumerating objects: 136, done.\u001b[K\n","remote: Counting objects: 100% (136/136), done.\u001b[K\n","remote: Compressing objects: 100% (107/107), done.\u001b[K\n","remote: Total 136 (delta 30), reused 86 (delta 15), pack-reused 0\u001b[K\n","Receiving objects: 100% (136/136), 16.10 MiB | 25.56 MiB/s, done.\n","Resolving deltas: 100% (30/30), done.\n"]}]},{"cell_type":"code","metadata":{"id":"mq0aH0PaF06z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636178372397,"user_tz":-330,"elapsed":4189,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"09cf13c0-53de-4164-a3fc-7a366e718b68"},"source":["! pip install git+https://github.com/cocodataset/panopticapi.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/cocodataset/panopticapi.git\n","  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-vr96cms3\n","  Running command git clone -q https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-vr96cms3\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from panopticapi==0.1) (1.19.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from panopticapi==0.1) (7.1.2)\n","Building wheels for collected packages: panopticapi\n","  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8306 sha256=4821143a2e61313b16bba79816c87411334f5fa30e4fcfa714c0174e85fb395e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9x_giuux/wheels/ad/89/b8/b66cce9246af3d71d65d72c85ab993fd28e7578e1b0ed197f1\n","Successfully built panopticapi\n","Installing collected packages: panopticapi\n","Successfully installed panopticapi-0.1\n"]}]},{"cell_type":"code","metadata":{"id":"LSSFZO3xieU5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636205836787,"user_tz":-330,"elapsed":2280,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"3e81b4a8-eaf6-4b74-c731-13134aa31bcc"},"source":["import os\n","import sys\n","import numpy as np\n","import torch\n","from torch import nn\n","torch.set_grad_enabled(False);\n","print(torch.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu111\n"]}]},{"cell_type":"code","metadata":{"id":"1wU298KGs0oT"},"source":["sys.path.append(os.path.join(os.getcwd(), \"/content/EVA6_Capstone/\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xyyRuTiViv9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636205840157,"user_tz":-330,"elapsed":59,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"baad5c16-5282-46f8-f873-870dcda57386"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","use_cuda, device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(True, device(type='cuda'))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"rWawN1FvjhEw"},"source":["import torchvision.transforms as T\n","\n","# standard PyTorch mean-std input image normalization\n","transform = T.Compose([\n","    T.Resize(800),\n","    T.ToTensor(),\n","    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhgEIGMLkAfA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636205856472,"user_tz":-330,"elapsed":4288,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"2b43f75c-a4ac-40d2-de08-c32ea66c4e82"},"source":["# Load detr model\n","model, postprocessor = torch.hub.load('facebookresearch/detr', 'detr_resnet101_panoptic', pretrained=True, return_postprocessor=True, num_classes=250)\n","# Convert to eval mode\n","model = model.to(device)\n","model.eval()\n","\n","print(\"Model Loaded\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/facebookresearch_detr_master\n"]},{"output_type":"stream","name":"stdout","text":["Model Loaded\n"]}]},{"cell_type":"code","metadata":{"id":"f3VMMAR_k1Mh"},"source":["def convert(o):\n","    if isinstance(o, np.generic): return o.item()  \n","    raise TypeError"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tCNfkgKsY-Z"},"source":["from DatasetCreation import COCO_CATEGORIES, CUSTOM_CATEGORIES, COCO_NAMES, MAPPINGS, INFO, LICENSES, cat2id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5kc3AElJnJ_"},"source":["from DatasetCreation import get_original_mask, get_annotation_info, create_image_info"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OSOdhVf49pJ"},"source":["import datetime\n","import time\n","import json\n","import traceback\n","from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuqvJE8Y5Aa6"},"source":["from PIL import Image, ImageDraw, ImageFont\n","import requests\n","import panopticapi\n","from panopticapi.utils import id2rgb, rgb2id, IdGenerator\n","import io\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAS6XFySBiX-"},"source":["id2catdetail = {category['id']: category for category in CUSTOM_CATEGORIES}\n","\n","id_generator = IdGenerator(id2catdetail)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95rOTKFEk-EE"},"source":["ROOT_DIR = '/content/drive/MyDrive/EVA6/Capstone/dataset'\n","\n","processing_file = \"\"\n","processing_data = []\n","\n","image_id = 1\n","annotation_id = 1\n","segment_id = 1\n","\n","GLOBAL_COCO = {\n","    \"licenses\": LICENSES,\n","    \"info\": INFO,\n","    \"categories\": CUSTOM_CATEGORIES,\n","    \"annotations\": [],\n","    \"images\": []\n","}\n","\n","GLOBAL_PANOPTIC = {\n","    \"licenses\": LICENSES,\n","    \"info\": INFO,\n","    \"categories\": CUSTOM_CATEGORIES,\n","    \"annotations\": [],\n","    \"images\": []\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfHvKTsWkZ2r"},"source":["data_path = [\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/aac_blocks',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/adhesives',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/ahus',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/aluminium_frames_for_false_ceiling',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/chiller',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/concrete_mixer_machine',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/concrete_pump',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/control_panel',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/cu_piping',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/distribution_transformer',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/dump_truck_tipper_truck',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/emulsion_paint',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/enamel_paint',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/fine_aggregate',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/fire_buckets',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/fire_extinguishers',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/glass_wool',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/grader',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/hoist',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/hollow_concrete_blocks',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/hot_mix_plant',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/hydra_crane',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/interlocked_switched_socket',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/junction_box',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/lime',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/marble',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/metal_primer',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/pipe_fittings',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/rcc_hume_pipes',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/refrigerant_gas',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/river_sand',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/rmc_batching_plant',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/rmu_units',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/sanitary_fixtures',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/skid_steer_loader',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/smoke_detectors',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/split_units',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/structural_steel_channel',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/switch_boards_and_switches',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/texture_paint',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/threaded_rod',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/transit_mixer',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/vcb_panel',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/vitrified_tiles',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/vrf_units',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/water_tank',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/wheel_loader',\n","     '/content/drive/MyDrive/EVA6/Capstone/dataset/wood_primer'  \t  \t  \t  \n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYYDjSOdyfOC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634326538832,"user_tz":-330,"elapsed":3784834,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"c6f2e3cb-9b1f-4290-ba91-13eb63f43a44"},"source":["for category_path in data_path:\n","\n","    # store starting time\n","    start = time.time()\n","\n","    # get category name\n","    category_name = category_path.split(\"/\")[7]\n","    print(\"Processing Category:\", category_name)\n","\n","    # open category coco file\n","    with open(os.path.join(category_path, \"coco.json\"), \"r\") as coco_file:\n","        category_coco = json.load(coco_file)\n","        \n","    images_root = os.path.join(category_path, 'images')\n","    \n","    TEMP_COCO_IMAGES = {}\n","    \n","    # Run over all images\n","    for im in category_coco[\"images\"]:\n","        im['annotations'] = []\n","        TEMP_COCO_IMAGES[im['id']] = im\n","\n","   \n","    for ann in category_coco[\"annotations\"]:\n","        TEMP_COCO_IMAGES[ann['image_id']][\"annotations\"].append(ann)\n","      \n","    for i, image_coco in TEMP_COCO_IMAGES.items():\n","        # get image path\n","        ## This data can be used further for logging if failed while processing\n","        processing_file = os.path.join(images_root, image_coco['file_name'])\n","        processing_data = image_coco\n","        output_file_name = category_name + \"_\" + str(image_id) + \".jpg\"\n","        output_file_path = os.path.join(ROOT_DIR, \"images\", output_file_name)\n","        \n","        output_mask_name = category_name + \"_\" + str(image_id) + \".png\"\n","        output_mask_path = os.path.join(ROOT_DIR, \"masks\", output_mask_name)\n","\n","        try:\n","\n","          # Read this image and get shape of image\n","          imo = Image.open(processing_file).convert('RGB')\n","\n","          try:\n","              h, w, c = np.array(imo).shape\n","          except:\n","              h, w = np.array(imo).shape\n","              c = 1\n","\n","          # if no of channels != 3, open the image and convert it to 3 channel - RGB\n","          if c == 4 or c == 1:\n","              imo = imo.convert('RGB')\n","              h, w, c = np.array(imo).shape\n","\n","          # Create a copy of image this will be used for further processing\n","          im = imo.copy()\n","\n","          # Apply transform and convert image to batch\n","          # mean-std normalize the input image (batch-size: 1)\n","          img = transform(im).unsqueeze(0).to(device)  # [h, w, c] -> [1, c, ht, wt]\n","\n","          # Generate output for image\n","          out = model(img)\n","\n","          # Generate score\n","          # compute the scores, excluding the \"no-object\" class (the last one)\n","          scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n","\n","          # threshold the confidence\n","          keep = scores > 0.85\n","\n","          # Keep only ones above threshold\n","          pred_logits, pred_boxes = out[\"pred_logits\"][keep][:, :len(COCO_NAMES) - 1], out[\"pred_boxes\"][keep]    \n","\n","          # the post-processor expects as input the target size of the predictions (which we set here to the image size)\n","          result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]    \n","\n","          # The segmentation is stored in a special-format png\n","          panoptic_seg = Image.open(io.BytesIO(result['png_string'])).resize((w, h), Image.NEAREST)\n","\n","           # (wp, hp) = panoptic_seg.size\n","          panoptic_seg = np.array(panoptic_seg, dtype=np.uint8).copy()   \n","\n","          # We retrieve the ids corresponding to each mask\n","          panoptic_seg_id = rgb2id(panoptic_seg)\n","\n","          # Merge predicted annotations      \n","          # 1. Get Mapping from predicted category id to new category ids\n","          unique_category_id = []\n","          for i, segment in enumerate(result['segments_info']):\n","              result['segments_info'][i][\"category_id\"] = MAPPINGS[result['segments_info'][i][\"category_id\"]]\n","              if result['segments_info'][i][\"category_id\"] not in unique_category_id:\n","                  unique_category_id.append(result['segments_info'][i][\"category_id\"])\n","\n","          # Sort array\n","          unique_category_id.sort()\n","\n","          unique_category_id_to_id =  {category_id: i for i, category_id in enumerate(unique_category_id)}\n","          unique_id_to_category_id =  {i: category_id for category_id, i in unique_category_id_to_id.items()}   \n","\n","          for i, segment in enumerate(result['segments_info']):\n","              result['segments_info'][i][\"new_id\"] = unique_category_id_to_id[result['segments_info'][i][\"category_id\"]]\n","\n","          # Update original panoptic_seg_id array with new ids as the new segmentation combines different categories.\n","          custom_panoptic_seg_id = np.zeros((panoptic_seg_id.shape[0], panoptic_seg_id.shape[1]), dtype=np.uint8)\n","          \n","          # Update this custom panoptic seg matrix\n","          for i, segment in enumerate(result['segments_info']):\n","              custom_panoptic_seg_id[result['segments_info'][i]['id'] == panoptic_seg_id] = result['segments_info'][i]['new_id']\n","\n","          # Create new Segmentation info         \n","          custom_panoptic_segments_info = []\n","          for category_id in unique_category_id:\n","              custom_panoptic_segments_info.append({\n","                  'segment_id': unique_category_id_to_id[category_id], \n","                  'category_id': category_id,\n","                  'bbox': [],\n","                  'area': 0,\n","                  'iscrowd': 0,\n","                  'isthing': 0\n","              })\n","\n","          # annotations of our construction things\n","          omask = processing_data['annotations']\n","          \n","          TEMP_ANNOTATIONS = []\n","\n","          # Overlay things mask one at a time\n","          for annotation in omask:\n","              # overlay mask of construction things on top of detr output\n","              omask_image_id = get_original_mask((h, w), annotation)\n","              custom_panoptic_seg_id[omask_image_id.astype(np.bool_)] = custom_panoptic_seg_id.max() + 1\n","              custom_panoptic_segments_info.append({\n","                  'segment_id': custom_panoptic_seg_id.max(), \n","                  'category_id': cat2id[category_name], \n","                  'bbox': annotation['bbox'],\n","                  'area': annotation['area'],\n","                  'iscrowd': 0,\n","                  'isthing': 1\n","              })\n","\n","              # append annotation of construction things in json file\n","              annotation[\"category_id\"] = cat2id[category_name]\n","              annotation[\"image_id\"] = image_id\n","              annotation[\"id\"] = custom_panoptic_seg_id.max()\n","              TEMP_ANNOTATIONS.append(annotation)\n","\n","          # Convert to binary segment\n","          binary_masks = np.zeros((\n","              custom_panoptic_seg_id.max() + 1,\n","              custom_panoptic_seg_id.shape[0],\n","              custom_panoptic_seg_id.shape[1]),\n","              dtype=np.uint8\n","          )\n","\n","          # for each binary mask, detect contours and create annotation for those contours\n","          if len(unique_category_id):\n","              # Skip the ones which are added by us\n","              for category_id in unique_category_id:\n","                  binary_masks[unique_category_id_to_id[category_id], :, :] = custom_panoptic_seg_id == unique_category_id_to_id[category_id]\n","                  annotation_info = get_annotation_info(binary_masks[unique_category_id_to_id[category_id]], None, image_id, category_id, unique_category_id_to_id[category_id], 0)\n","                  \n","                  if annotation_info is not None:\n","                      TEMP_ANNOTATIONS.append(annotation_info) \n","                      custom_panoptic_segments_info[unique_category_id_to_id[category_id]]['bbox'] = annotation_info['bbox']\n","                      custom_panoptic_segments_info[unique_category_id_to_id[category_id]]['area'] = annotation_info['area']   \n","          else:\n","              # Do something for the once where there are no predictions\n","              ## Probably mark them as None\n","              pass\n","\n","          # Write data to global json and save files to image dir's\n","          # save image to new path as .jpg\n","          imo.save(output_file_path)\n","\n","          # save panoptic image\n","          Image.fromarray(id2rgb(custom_panoptic_seg_id), 'RGB').save(output_mask_path)\n","\n","          # Create a new empty id array\n","          panoptic_seg_id_corrected = np.zeros(custom_panoptic_seg_id.shape)\n","\n","          # All unique segments in original id image\n","          unique_panoptic_seg_id = np.unique(custom_panoptic_seg_id)\n","          \n","          # All segments for which masks are available\n","          segms_corrected = []\n","\n","          # Finally we get id for each mask individually\n","          for segm in custom_panoptic_segments_info:\n","\n","              # Original Segment id\n","              segment_id = segm[\"segment_id\"]\n","              \n","              if segment_id in unique_panoptic_seg_id:\n","                  # Get new Segment Id\n","                  proper_id = id_generator.get_id(segm['category_id'])\n","                  # Populate these new segments id\n","                  panoptic_seg_id_corrected[custom_panoptic_seg_id==segm[\"segment_id\"]] = proper_id\n","                  # Update segm annotation json\n","                  segm['id'] = proper_id\n","                  # if segm id is less than max value for original mask print it\n","                  if proper_id < panoptic_seg_id.max()+1:\n","                      print(proper_id)\n","                      \n","                  # Append this Segment\n","                  segms_corrected.append(segm)\n","                  \n","          # Update original segments_info\n","          custom_panoptic_segments_info = segms_corrected\n","          \n","          # Save Image\n","          Image.fromarray(id2rgb(panoptic_seg_id_corrected), 'RGB').save(f\"/content/drive/MyDrive/EVA6/Capstone/dataset/panoptic/{output_mask_name}\")\n","\n","          # create image_info object and append it to original list\n","          image_info = create_image_info(image_id, output_file_name, imo.size)\n","          image_info[\"original_file\"] = processing_file\n","\n","          # Only consider images where segment info is correctly available\n","          if len(segms_corrected):\n","            GLOBAL_COCO[\"images\"].append(image_info)\n","            GLOBAL_PANOPTIC[\"images\"].append(image_info)\n","\n","            for annotation in TEMP_ANNOTATIONS:\n","                annotation[\"id\"] = annotation_id\n","                GLOBAL_COCO[\"annotations\"].append(annotation)\n","                annotation_id += 1\n","              \n","            for segment_info in custom_panoptic_segments_info:\n","                # segment_info[\"id\"] = segment_id\n","                segment_id += 1\n","\n","            GLOBAL_PANOPTIC[\"annotations\"].append({\n","                \"segments_info\": custom_panoptic_segments_info,\n","                \"file_name\": output_mask_name,\n","                \"image_id\": image_id\n","            })\n","\n","          # increment the image_count\n","          image_id += 1\n","\n","\n","        except Exception as e:\n","            # if there is any error, add info about it in errros file and procees to next image\n","            print(\"Error occurred while processig file:\", processing_file)\n","            \n","            with open(os.path.join(ROOT_DIR, \"error.json\"), 'r') as error_file:\n","                error_json = json.load(error_file)\n","                \n","            with open(os.path.join(ROOT_DIR, \"error.json\"), 'w') as error_file:\n","                error_json[\"error\"].append({\n","                    \"processing_file\": processing_file,\n","                    \"processing_data\": processing_data\n","                })\n","                \n","                json.dump(error_json, error_file)\n","                \n","            traceback.print_exc()\n","\n","        del img, out, scores, keep, pred_logits, pred_boxes, result,panoptic_seg_id, panoptic_seg \n","        torch.cuda.empty_cache() \n","      \n","    total_time_str = str(datetime.timedelta(seconds=int(time.time() - start)))\n","    print(f\"Completed Category: {category_name}, Time Taken: {total_time_str}\")\n","\n","    # open the final json, and commit changes in that file\n","    with open(os.path.join(ROOT_DIR, \"coco.json\"), 'w') as output_json_file:\n","        json.dump(GLOBAL_COCO, output_json_file)\n","        \n","    with open(os.path.join(ROOT_DIR, \"panoptic.json\"), 'w') as output_json_file:\n","        json.dump(GLOBAL_PANOPTIC, output_json_file, default=convert)\n","        \n","    print(image_id, annotation_id, segment_id)   "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Category: skid_steer_loader\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]},{"output_type":"stream","name":"stdout","text":["Completed Category: skid_steer_loader, Time Taken: 0:02:01\n","6590 23905 24023\n","Processing Category: smoke_detectors\n","Completed Category: smoke_detectors, Time Taken: 0:00:46\n","6640 23999 24117\n","Processing Category: split_units\n","Completed Category: split_units, Time Taken: 0:07:49\n","7178 25666 25796\n","Processing Category: structural_steel_channel\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"]},{"output_type":"stream","name":"stdout","text":["Completed Category: structural_steel_channel, Time Taken: 0:04:09\n","7579 26563 26694\n","Processing Category: switch_boards_and_switches\n","Completed Category: switch_boards_and_switches, Time Taken: 0:05:17\n","8079 27599 27763\n","Processing Category: texture_paint\n","Completed Category: texture_paint, Time Taken: 0:00:31\n","8131 27702 27868\n","Processing Category: threaded_rod\n","Error occurred while processig file: /content/drive/MyDrive/EVA6/Capstone/dataset/threaded_rod/images/img_052.jpg\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"<ipython-input-29-155ae7a1607d>\", line 42, in <module>\n","    imo = Image.open(processing_file).convert('RGB')\n","  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2843, in open\n","    fp = builtins.open(filename, \"rb\")\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/EVA6/Capstone/dataset/threaded_rod/images/img_052.jpg'\n"]},{"output_type":"stream","name":"stdout","text":["Error occurred while processig file: /content/drive/MyDrive/EVA6/Capstone/dataset/threaded_rod/images/img_050.jpg\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"<ipython-input-29-155ae7a1607d>\", line 42, in <module>\n","    imo = Image.open(processing_file).convert('RGB')\n","  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2843, in open\n","    fp = builtins.open(filename, \"rb\")\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/EVA6/Capstone/dataset/threaded_rod/images/img_050.jpg'\n"]},{"output_type":"stream","name":"stdout","text":["Completed Category: threaded_rod, Time Taken: 0:21:32\n","8682 29041 29207\n","Processing Category: transit_mixer\n","Completed Category: transit_mixer, Time Taken: 0:00:40\n","8732 29290 29456\n","Processing Category: vcb_panel\n","Completed Category: vcb_panel, Time Taken: 0:06:51\n","9232 30979 31166\n","Processing Category: vitrified_tiles\n","Completed Category: vitrified_tiles, Time Taken: 0:04:21\n","9632 32510 32733\n","Processing Category: vrf_units\n","Completed Category: vrf_units, Time Taken: 0:00:37\n","9682 32632 32855\n","Processing Category: water_tank\n","Completed Category: water_tank, Time Taken: 0:03:31\n","9986 34003 34229\n","Processing Category: wheel_loader\n","Completed Category: wheel_loader, Time Taken: 0:02:06\n","10136 34697 34931\n","Processing Category: wood_primer\n","Completed Category: wood_primer, Time Taken: 0:00:09\n","10148 34726 34961\n"]}]},{"cell_type":"code","metadata":{"id":"z8yVJ47glKn-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634326574214,"user_tz":-330,"elapsed":331,"user":{"displayName":"Gokul P V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01488576985730312631"}},"outputId":"c5d5de8b-2826-4c85-8f71-93fa4dbae0cf"},"source":["# setting device on GPU if available, else CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","Tesla P100-PCIE-16GB\n","Memory Usage:\n","Allocated: 0.3 GB\n","Cached:    0.9 GB\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:375: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"LOcf27MlmGbz"},"source":["torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]}]}